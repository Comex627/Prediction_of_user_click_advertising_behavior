{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "sns.set(font_scale=1)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "label = pd.read_csv('train_label.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sub = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = train.merge(label,on='ID',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = -1\n",
    "train = train.merge(label,on='ID',how='left')\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_fe(df):\n",
    "    df['day'] = df.date.apply(lambda x:int(x[8:10]))\n",
    "\n",
    "    df['hour'] = df.date.apply(lambda x:int(x[11:13]))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对时间分箱\n",
    "def getSeg(x):\n",
    "    if x >=0 and x<= 6:\n",
    "        return 1\n",
    "    elif x>=7 and x<=12:\n",
    "        return 2\n",
    "    elif x>=13 and x<=18:\n",
    "        return 3\n",
    "    elif x>=19 and x<=23:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourDF = train_df.groupby(['hour', 'label'])['hour'].count().unstack('label').fillna(0)\n",
    "# hourDF[[0,1]].plot(kind='bar', stacked=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count统计特征\n",
    "cross_feature = []\n",
    "def get_cross_fe(df):\n",
    "    first_feature = ['B1', 'B2', 'B3']\n",
    "    second_feature = ['C1','C2','C3','D1','D2']\n",
    "    for feat_1 in first_feature:\n",
    "        for feat_2 in second_feature:\n",
    "            col_name = \"cross_\" + feat_1 + \"_and_\" + feat_2\n",
    "            cross_feature.append(col_name)\n",
    "            df[col_name] = df[feat_1].astype(str).values + '_' + df[feat_2].astype(str).values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_time_fe(data)\n",
    "# data['hour_seg'] = data['hour'].apply(lambda x: getSeg(x))\n",
    "data = get_cross_fe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelencoder()\n",
    "cate_feature = ['A1','A2','A3','B1','B2','B3','C1','C2','C3','E2','E3','E5','E7','E9','E10','E13','E16','E17','E19','E21','E22']\n",
    "cross_feature = cross_feature[:15]\n",
    "cate_features = cate_feature+cross_feature\n",
    "for item in cate_features:\n",
    "    data[item] = LabelEncoder().fit_transform(data[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_count(data, features=[]):\n",
    "    new_feature = 'count'\n",
    "    for i in features:\n",
    "        new_feature += '_' + i\n",
    "    try:\n",
    "        del data[new_feature]\n",
    "    except:\n",
    "        pass\n",
    "    temp = data.groupby(features).size().reset_index().rename(columns={0: new_feature})\n",
    "    data = data.merge(temp, 'left', on=features)\n",
    "    return data\n",
    "\n",
    "for i in cross_feature:\n",
    "    n = data[i].nunique()\n",
    "    if n > 5:\n",
    "        data = feature_count(data, [i])\n",
    "    else:\n",
    "        print(i, ':', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin ratio clcik...\n",
      "The end\n"
     ]
    }
   ],
   "source": [
    "#ratio：类别偏好的ratio比例特征\n",
    "label_feature =[ 'A2', 'A3']\n",
    "data_temp = data[label_feature]\n",
    "df_feature = pd.DataFrame()\n",
    "data_temp['cnt'] = 1\n",
    "print('Begin ratio clcik...')\n",
    "col_type = label_feature.copy()\n",
    "n = len(col_type)\n",
    "for i in range(n):\n",
    "    col_name = \"ratio_click_of_\" + col_type[i]\n",
    "    df_feature[col_name] = (\n",
    "                    data_temp[col_type[i]].map(data_temp[col_type[i]].value_counts()) / len(data) * 100).astype(int)            \n",
    "data = pd.concat([data, df_feature], axis=1)\n",
    "print('The end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data[data['label'] != -1]\n",
    "test_df = data[data['label'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.stripplot(train_df[\"label\"],train_df[\"A3\"],jitter=True,order=None)\n",
    "# plt.title(\"click Vs creative_height\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 删除不需要的字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get train feature\n",
    "del_feature = ['ID','day','date','label','D2']+cross_feature\n",
    "features = [i for i in train_df.columns if i not in del_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df[features]\n",
    "train_y = train_df['label'].values\n",
    "test = test_df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练参数的选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'gamma': 0.1,\n",
    "    'max_depth': 8,\n",
    "    'alpha': 0,\n",
    "    'lambda': 0,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'min_child_weight': 3,\n",
    "    'silent': 0,\n",
    "    'eta': 0.03,\n",
    "    'nthread': -1,\n",
    "    'missing': 1,\n",
    "    'seed': 2019,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五折交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=2048)\n",
    "prob_oof = np.zeros((train_x.shape[0], ))\n",
    "test_pred_prob = np.zeros((test.shape[0], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "[0]\ttrain-auc:0.701995\tvalid-auc:0.683243\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.812831\tvalid-auc:0.718542\n",
      "[400]\ttrain-auc:0.856727\tvalid-auc:0.718052\n",
      "Stopping. Best iteration:\n",
      "[237]\ttrain-auc:0.82262\tvalid-auc:0.719363\n",
      "\n",
      "fold 2\n",
      "[0]\ttrain-auc:0.688389\tvalid-auc:0.682834\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.808243\tvalid-auc:0.737984\n",
      "[400]\ttrain-auc:0.856792\tvalid-auc:0.739812\n",
      "Stopping. Best iteration:\n",
      "[308]\ttrain-auc:0.836002\tvalid-auc:0.74022\n",
      "\n",
      "fold 3\n",
      "[0]\ttrain-auc:0.699694\tvalid-auc:0.684989\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.81124\tvalid-auc:0.728952\n",
      "[400]\ttrain-auc:0.858242\tvalid-auc:0.727978\n",
      "Stopping. Best iteration:\n",
      "[277]\ttrain-auc:0.831197\tvalid-auc:0.730053\n",
      "\n",
      "fold 4\n",
      "[0]\ttrain-auc:0.705635\tvalid-auc:0.667286\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.812105\tvalid-auc:0.711489\n",
      "[400]\ttrain-auc:0.859481\tvalid-auc:0.714059\n",
      "Stopping. Best iteration:\n",
      "[334]\ttrain-auc:0.845914\tvalid-auc:0.714345\n",
      "\n",
      "fold 5\n",
      "[0]\ttrain-auc:0.687865\tvalid-auc:0.663092\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.81233\tvalid-auc:0.719231\n",
      "[400]\ttrain-auc:0.856904\tvalid-auc:0.719261\n",
      "Stopping. Best iteration:\n",
      "[309]\ttrain-auc:0.839233\tvalid-auc:0.720432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_round = 1000\n",
    "feature_importance_df = pd.DataFrame()\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train)):\n",
    "    print(\"fold {}\".format(fold_ + 1))\n",
    "    trn_data = xgb.DMatrix(train_x.iloc[trn_idx], label=train_y[trn_idx])\n",
    "    val_data = xgb.DMatrix(train_x.iloc[val_idx], label=train_y[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid')]\n",
    "    clf = xgb.train(params, trn_data, num_round, watchlist, verbose_eval=200, early_stopping_rounds=200)\n",
    "\n",
    "    prob_oof[val_idx] = clf.predict(xgb.DMatrix(train_x.iloc[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = clf.get_fscore().keys()\n",
    "    fold_importance_df[\"importance\"] = clf.get_fscore().values()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    test_pred_prob += clf.predict(xgb.DMatrix(test), ntree_limit=clf.best_ntree_limit) / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# roc评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7246375402554077"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=roc_auc_score(train_y,prob_oof)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['label'] = test_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['label'] = sub['label'].apply(lambda x:'%.2f'%x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    49756\n",
       "1    10244\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('C:/Users/DELL/Desktop/sub/'+str('%.6f'%score)+'xgb.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature_importance展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot feature importance\n",
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]].groupby(\"Feature\").mean().sort_values(by=\"importance\", ascending=False).index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)].sort_values(by='importance',ascending=False)\n",
    "plt.figure(figsize=(8, 15))\n",
    "sns.barplot(y=\"Feature\",\n",
    "            x=\"importance\",\n",
    "            data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_more_fe(df):\n",
    "#     uniq_list = ['C1','E14','A2','E1','E27']\n",
    "#     for i in uniq_list:\n",
    "#         tmp = df.groupby(['hour'])[i].nunique().reset_index(name = i+'_h_uniq')\n",
    "#         df  = df.merge(tmp, on=['hour'], how='left')\n",
    "#         tmp1 = df.groupby(['date'])[i].nunique().reset_index(name = i+'_d_uniq')\n",
    "#         df  = df.merge(tmp1, on=['date'], how='left')\n",
    "#     dev_list = ['D1','D2']\n",
    "#     for i in dev_list:\n",
    "#         tmp = df.groupby(['C1'])[i].nunique().reset_index(name = i+'_C1_de_uniq')\n",
    "#         df  = df.merge(tmp, on=['C1'], how='left')\n",
    "#         tmp1 = df.groupby(['C2'])[i].nunique().reset_index(name = i+'_C2_de_uniq')\n",
    "#         df  = df.merge(tmp1, on=['C2'], how='left')\n",
    "#         tmp2 = df.groupby(['C3'])[i].nunique().reset_index(name = i+'_C3_de_uniq')\n",
    "#         df  = df.merge(tmp2, on=['C3'], how='left')\n",
    "#     return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
