{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "sns.set(font_scale=1)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "label = pd.read_csv('train_label.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sub = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = train.merge(label,on='ID',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = -1\n",
    "train = train.merge(label,on='ID',how='left')\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_fe(df):\n",
    "    df['day'] = df.date.apply(lambda x:int(x[8:10]))\n",
    "\n",
    "    df['hour'] = df.date.apply(lambda x:int(x[11:13]))\n",
    "    \n",
    "#     df['d_h'] = df['day'].astype('int')*24+df['hour'].astype('int')\n",
    "    \n",
    "#     result = df[df['label']!=-1].groupby(['d_h']).label.agg(['count','sum']).reset_index()\n",
    "    \n",
    "#     result['click_prob'] = (result['sum'].astype('int')/result['count'].astype('int'))\n",
    "    \n",
    "#     df = df.merge(result,on=['d_h'],how = 'left')\n",
    "    \n",
    "#     del result['count'],result['sum'],result['d_h']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# szy = get_time_fe(data)\n",
    "# result = szy[szy['label']!=-1].groupby(['hour']).label.agg(['count','sum']).reset_index()\n",
    "# result['click_prob'] = (result['sum'].astype('int')/result['count'].astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对时间分箱\n",
    "def getSeg(x):\n",
    "    if x >=0 and x<= 3:\n",
    "        return 1\n",
    "    elif x>=4 and x<=12:\n",
    "        return 2\n",
    "    elif x>=13 and x<=18:\n",
    "        return 3\n",
    "    elif x>=19 and x<=23:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourDF = train_df.groupby(['hour', 'label'])['hour'].count().unstack('label').fillna(0)\n",
    "# hourDF[[0,1]].plot(kind='bar', stacked=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count统计特征\n",
    "cross_feature = []\n",
    "def get_cross_fe(df):\n",
    "    first_feature = [ 'B2', 'B3']\n",
    "    second_feature = ['C1','C2','C3','D1','A1','A2','A3']\n",
    "    for feat_1 in first_feature:\n",
    "        for feat_2 in second_feature:\n",
    "            col_name = \"cross_\" + feat_1 + \"_and_\" + feat_2\n",
    "            cross_feature.append(col_name)\n",
    "            df[col_name] = df[feat_1].astype(str).values + '_' + df[feat_2].astype(str).values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取nunique特征\n",
    "def get_nunique_1_fe(df):\n",
    "    adid_nuq = [ 'hour','E1','E14','B2','B3']\n",
    "    for feat in adid_nuq:\n",
    "        gp1 = df.groupby('A2')[feat].nunique().reset_index().rename(columns={feat: \"A2_%s_nuq_num\" % feat})\n",
    "        gp2 = df.groupby(feat)['A2'].nunique().reset_index().rename(columns={'A2': \"%s_A2_nuq_num\" % feat})\n",
    "        df = pd.merge(df, gp1, how='left', on=['A2'])\n",
    "        df = pd.merge(df, gp2, how='left', on=[feat])\n",
    "    return df\n",
    "def get_nunique_2_fe(df):\n",
    "    adid_nuq = [ 'E1','E14']\n",
    "    for feat in adid_nuq:\n",
    "        gp1 = df.groupby('hour')[feat].nunique().reset_index().rename(columns={feat: \"hour_%s_nuq_num\" % feat})\n",
    "        gp2 = df.groupby(feat)['hour'].nunique().reset_index().rename(columns={'hour': \"%s_hour_nuq_num\" % feat})\n",
    "        df = pd.merge(df, gp1, how='left', on=['hour'])\n",
    "        df = pd.merge(df, gp2, how='left', on=[feat])\n",
    "    return df\n",
    "\n",
    "# def get_nunique_3_fe(df):\n",
    "#     adid_nuq = ['B2','B3']\n",
    "#     for feat in adid_nuq:\n",
    "#         gp1 = df.groupby('A3')[feat].nunique().reset_index().rename(columns={feat: \"A3_%s_nuq_num\" % feat})\n",
    "#         gp2 = df.groupby(feat)['A3'].nunique().reset_index().rename(columns={'A3': \"%s_A3_nuq_num\" % feat})\n",
    "#         df = pd.merge(df, gp1, how='left', on=['A3'])\n",
    "#         df = pd.merge(df, gp2, how='left', on=[feat])\n",
    "#     return df\n",
    "\n",
    "def get_nunique_4_fe(df):\n",
    "    adid_nuq = [ 'B2','B3']\n",
    "    for feat in adid_nuq:\n",
    "        gp1 = df.groupby('A1')[feat].nunique().reset_index().rename(columns={feat: \"A1_%s_nuq_num\" % feat})\n",
    "        gp2 = df.groupby(feat)['A1'].nunique().reset_index().rename(columns={'A1': \"%s_A1_nuq_num\" % feat})\n",
    "        df = pd.merge(df, gp1, how='left', on=['A1'])\n",
    "        df = pd.merge(df, gp2, how='left', on=[feat])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_time_fe(data)\n",
    "# data['hour_seg'] = data['hour'].apply(lambda x: getSeg(x))\n",
    "data = get_cross_fe(data)\n",
    "data = get_nunique_1_fe(data)\n",
    "data = get_nunique_2_fe(data)\n",
    "# data = get_nunique_3_fe(data)\n",
    "# data = get_nunique_4_fe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cross_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelencoder()\n",
    "cate_feature = ['A1','A2','A3','B1','B2','B3','C1','C2','C3','E2','E3','E5','E7','E9','E10','E13','E16','E17','E19','E21','E22']\n",
    "# cross_feature = cross_feature[:15]\n",
    "cate_features = cate_feature+cross_feature\n",
    "for item in cate_features:\n",
    "    data[item] = LabelEncoder().fit_transform(data[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_count(data, features=[]):\n",
    "    new_feature = 'count'\n",
    "    for i in features:\n",
    "        new_feature += '_' + i\n",
    "    try:\n",
    "        del data[new_feature]\n",
    "    except:\n",
    "        pass\n",
    "    temp = data.groupby(features).size().reset_index().rename(columns={0: new_feature})\n",
    "    data = data.merge(temp, 'left', on=features)\n",
    "    return data\n",
    "\n",
    "for i in cross_feature:\n",
    "    n = data[i].nunique()\n",
    "    if n > 5:\n",
    "        data = feature_count(data, [i])\n",
    "    else:\n",
    "        print(i, ':', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin ratio clcik...\n",
      "The end\n"
     ]
    }
   ],
   "source": [
    "#ratio：类别偏好的ratio比例特征\n",
    "label_feature =[ 'A2', 'A3','hour']\n",
    "data_temp = data[label_feature]\n",
    "df_feature = pd.DataFrame()\n",
    "data_temp['cnt'] = 1\n",
    "print('Begin ratio clcik...')\n",
    "col_type = label_feature.copy()\n",
    "n = len(col_type)\n",
    "for i in range(n):\n",
    "    col_name = \"ratio_click_of_\" + col_type[i]\n",
    "    df_feature[col_name] = (\n",
    "                    data_temp[col_type[i]].map(data_temp[col_type[i]].value_counts()) / len(data) * 100).astype(int)            \n",
    "data = pd.concat([data, df_feature], axis=1)\n",
    "print('The end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data[data['label'] != -1]\n",
    "test_df = data[data['label'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_df = train_df.groupby([\"day\", \"hour\"])[\"label\"].aggregate(\"mean\").reset_index()\n",
    "# grouped_df = grouped_df.pivot('day', 'hour', 'label')\n",
    "# plt.figure(figsize=(12,6))\n",
    "# sns.heatmap(grouped_df)\n",
    "# plt.title(\"CVR of Day Vs Hour\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.stripplot(train_df[\"label\"],train_df[\"A3\"],jitter=True,order=None)\n",
    "# plt.title(\"click Vs creative_height\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 删除不需要的字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get train feature\n",
    "del_feature = ['ID','day','date','label','D2']+cross_feature\n",
    "features = [i for i in train_df.columns if i not in del_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df[features]\n",
    "train_y = train_df['label'].values\n",
    "test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params= {\n",
    "#    'num_leaves':97,\n",
    "#     'objective':'binary',\n",
    "#     'learning_rate':0.02,\n",
    "#    'max_bin':400,\n",
    "#    'min_data_in_leaf':10,\n",
    "#     'feature_fraction':0.164,\n",
    "#     'subsample':0.8,\n",
    "#     'subsample_freq':1,\n",
    "#    'bagging_freq':1,\n",
    "#    'bagging_seed':0,\n",
    "#     'min_split_gain':0.000135,\n",
    "#     'min_child_weight':5,\n",
    "#     'min_child_samples':30,\n",
    "#     'bagging_fraction':1,\n",
    "#     'metric': {'binary_logloss', 'auc'},\n",
    "\n",
    "#    'reg_alpha':3,\n",
    "#    'reg_lambda':5\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练参数的选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params= {\n",
    "   'num_leaves':97,\n",
    "    'objective':'binary',\n",
    "    'learning_rate':0.02,\n",
    "   'max_bin':400,\n",
    "   'min_data_in_leaf':10,\n",
    "    'feature_fraction':0.164,\n",
    "    'subsample':0.8,\n",
    "    'subsample_freq':1,\n",
    "   'bagging_freq':1,\n",
    "   'bagging_seed':0,\n",
    "    'min_split_gain':0.000135,\n",
    "    'min_child_weight':5,\n",
    "    'min_child_samples':30,\n",
    "    'bagging_fraction':1,\n",
    "    'metric': {'binary_logloss', 'auc'},\n",
    "\n",
    "   'reg_alpha':3,\n",
    "   'reg_lambda':0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五折交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits=10\n",
    "folds = KFold(n_splits=n_splits, shuffle=True, random_state=2048)\n",
    "prob_oof = np.zeros((train_x.shape[0], ))\n",
    "test_pred_prob = np.zeros((test.shape[0], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "Training until validation scores don't improve for 60 rounds.\n"
     ]
    }
   ],
   "source": [
    "num_round = 1000\n",
    "feature_importance_df = pd.DataFrame()\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df)):\n",
    "    print(\"fold {}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(train_x.iloc[trn_idx], label=train_y[trn_idx])\n",
    "    val_data = lgb.Dataset(train_x.iloc[val_idx], label=train_y[val_idx])\n",
    "    \n",
    "    clf = lgb.train(params,\n",
    "                    trn_data,\n",
    "                    num_boost_round=2048,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_feature,\n",
    "                    early_stopping_rounds=60)\n",
    "    prob_oof[val_idx] = clf.predict(train_x.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    test_pred_prob += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# roc评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=roc_auc_score(train_y,prob_oof)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['label'] = test_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['label'] = sub['label'].apply(lambda x:'%.2f'%x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('C:/Users/DELL/Desktop/sub/'+str('%.6f'%score)+'lgb_'+str(n_splits)+'.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature_importance展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot feature importance\n",
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]].groupby(\"Feature\").mean().sort_values(by=\"importance\", ascending=False)[:].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)].sort_values(by='importance',ascending=False)\n",
    "plt.figure(figsize=(8, 14))\n",
    "sns.barplot(y=\"Feature\",\n",
    "            x=\"importance\",\n",
    "            data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_more_fe(df):\n",
    "#     uniq_list = ['C1','E14','A2','E1','E27']\n",
    "#     for i in uniq_list:\n",
    "#         tmp = df.groupby(['hour'])[i].nunique().reset_index(name = i+'_h_uniq')\n",
    "#         df  = df.merge(tmp, on=['hour'], how='left')\n",
    "#         tmp1 = df.groupby(['date'])[i].nunique().reset_index(name = i+'_d_uniq')\n",
    "#         df  = df.merge(tmp1, on=['date'], how='left')\n",
    "#     dev_list = ['D1','D2']\n",
    "#     for i in dev_list:\n",
    "#         tmp = df.groupby(['C1'])[i].nunique().reset_index(name = i+'_C1_de_uniq')\n",
    "#         df  = df.merge(tmp, on=['C1'], how='left')\n",
    "#         tmp1 = df.groupby(['C2'])[i].nunique().reset_index(name = i+'_C2_de_uniq')\n",
    "#         df  = df.merge(tmp1, on=['C2'], how='left')\n",
    "#         tmp2 = df.groupby(['C3'])[i].nunique().reset_index(name = i+'_C3_de_uniq')\n",
    "#         df  = df.merge(tmp2, on=['C3'], how='left')\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# params= {\n",
    "#    'num_leaves':97,\n",
    "#     'objective':'binary',\n",
    "#     'learning_rate':0.02,\n",
    "#    'max_bin':400,\n",
    "#    'min_data_in_leaf':10,\n",
    "#     'feature_fraction':0.164,\n",
    "#     'subsample':0.8,\n",
    "#     'subsample_freq':1,\n",
    "#    'bagging_freq':1,\n",
    "#    'bagging_seed':0,\n",
    "#     'min_split_gain':0.000135,\n",
    "#     'min_child_weight':5,\n",
    "#     'min_child_samples':30,\n",
    "#     'bagging_fraction':1,\n",
    "#     'metric': {'binary_logloss', 'auc'},\n",
    "\n",
    "#    'reg_alpha':3,\n",
    "#    'reg_lambda':0\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
